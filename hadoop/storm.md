# Storm
Storm 은 실시간 분석 분산 시스템이다. Hadoop과 비교하여 Hadoop은 빅데이터를 배치 Job으로 처리하기 때문에 실시간 데이터 처리가 필요한 경우에 
제한받는 부분이 있다. Storm 은 토폴로지 작업을 통해 실시간으로 데이터를 처리한다. 
> 스트리밍 처리에 있어서 대표적인 프레임워크로 Spark 도 있지만, Spark보다 보편적인 분산형 컴퓨팅을 지원하고 안정성 부분에서 아직은 Storm가 우위로 보임

## Topology
Hadoop에서는 MR 작업을 실행하지만, Storm에서는 토폴로지 작업을 수행한다. MR과 가장 큰 차이점은 MR 은 작업을 시작하고 '완료'하지만 토폴로지는 계속해서 
데이터를 처리하며 영구적 또는 수동으로 중지할 때 까지 실행되는 것이 디폴트이다. 
토폴로지는 데이터를 읽어올 스트림을 정의하고(Spout) 읽어들인 스트림을 처리할 처리 로직(Bolt)을 포함한다.
토폴로지가 시작되면 스파우트는 시스템으로 데이터를 가져와서 볼트로 데이터를 넘긴다. 

### Spout
Storm 토폴로지의 entry point. 스파우트는 데이터는 토폴로지로 가져와서 하나 이상의 스트림을 토폴로지로 내보낸다. 
- `open()` : Spout이 처음 초기화 될때 한번만 호출되는 함수. 데이타 소스로 부터의 연결을 초기화 하는 등의 역할
- `nextTuple()` : 데이터 스트림 하나를 읽고 나서 다음 데이터 스트림을 읽을 때 호출 되는 함수
- `ack(Object msgId)` : 데이터 스트림이 성공적으로 처리되었을때 호출, 이 메서드에서는 성공 처리된 메세지를 지우는 등, 성공 처리에 대한 후처리를 구현
- `fail(Object msgId)` : 데이타 스트림이 토폴로지를 수행하던중에, 에러가 나거나 타임아웃등이 걸렸을때 호출. 이때에는 사용자가 에러에 대한 에처 처리 로직을 명시해야 함.
흔히 재처리 로직을 구현하거나 또는 에러 로깅등의 처리를 하게 됨

### Bolt
볼트는 실제 처리 로직을 포함한다. 볼트는 스파우트나 또 다른 볼트에서 내보낸 스트림을 사용한다. 
스트림에서만 작동하며 스트림을 다른 볼트로 추가 처리하기 위해 스트림을 내보낼 수도 있고 영구 저장을 위해 데이터를 내보내거나 저장할 수도 있다.
또한 Bolt는 HDFS, Kafka 또는 HBase와 같은 외부 서비스 또는 저장소에 데이터를 쓰는 역할을 수행할 수 있다. 
- `prepare(Map stormConf, TopologyContext context, OutputCollector collector)`: 
Bolt 객체가 생성될때 한번 호출. 각종 설정 정보나 컨텍스트등 초기 설정에 필요한 부분을 세팅
- `execute(Tuple input)`: Bolt에 들어온 메세지를 처리하는 로직(필수적). 종단 Bolt가 아닌 경우에는 다음 Bolt로 메세지를 전달하기도 함

### Stream
Storm 의 핵심 추상화. 튜플은 Storm 의 가장 기본적인 데이터 구조이고, 스트림은 묶이지 않은 일련의 튜플(키 값 쌍의 모음)이다.

## Architecture
### Nimbus
- hdfs의 네임노드, Hadoop의 JobTracker와 유사. 마스터 노드 역할
- 토폴로지를 받아서 각 supervisor에게 배포하고 작업을 수행 및 추적

### Worker
- 각 Worker 노드는 Supervisor 라고 하는 데몬을 실행시킴
- 실제 컴포넌트(Bolt, Spout)가 할당되어 task를 수행

### Supervisor
- Nimbus로부터 명령을 받아서 Worker 프로세스로 구동
